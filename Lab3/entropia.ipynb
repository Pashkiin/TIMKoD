{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rtoit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample0.txt, Entropy of words: 7.7487413861401295\n",
      "sample0.txt, Entropy of characters: 4.273001240566633\n",
      "sample1.txt, Entropy of words: 11.500700199498642\n",
      "sample1.txt, Entropy of characters: 4.1270061355497205\n",
      "sample2.txt, Entropy of words: 8.023869815826425\n",
      "sample2.txt, Entropy of characters: 3.9933118002325836\n",
      "sample3.txt, Entropy of words: 9.061122986146984\n",
      "sample3.txt, Entropy of characters: 3.9302978341579875\n",
      "sample4.txt, Entropy of words: 17.129669111070662\n",
      "sample4.txt, Entropy of characters: 4.253809567379015\n",
      "sample5.txt, Entropy of words: 16.509437287775633\n",
      "sample5.txt, Entropy of characters: 4.441688018481797\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.probability import FreqDist\n",
    "import math\n",
    "\n",
    "norm_files_list = ['norm_wiki_en.txt', 'norm_wiki_eo.txt', 'norm_wiki_et.txt', 'norm_wiki_ht.txt', 'norm_wiki_la.txt', 'norm_wiki_nv.txt', 'norm_wiki_so.txt']\n",
    "sample_files_list = ['sample0.txt', 'sample1.txt', 'sample2.txt', 'sample3.txt', 'sample4.txt', 'sample5.txt']\n",
    "\n",
    "#initialize lists to store entropy values\n",
    "entropy_words_list = []\n",
    "entropy_chars_list = []\n",
    "\n",
    "#clear the result file\n",
    "with open('sample_results.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('')\n",
    "\n",
    "#repeat operation for all files in the list\n",
    "for file in sample_files_list:\n",
    "    # Open and read the file\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Tokenize the text into words and characters\n",
    "    words = nltk.word_tokenize(text)\n",
    "    chars = list(text)\n",
    "\n",
    "    # Calculate the frequency distribution\n",
    "    fdist_words = FreqDist(words)\n",
    "    fdist_chars = FreqDist(chars)\n",
    "\n",
    "    # Calculate the probabilities\n",
    "    prob_words = {word: freq / len(words) for word, freq in fdist_words.items()}\n",
    "    prob_chars = {char: freq / len(chars) for char, freq in fdist_chars.items()}\n",
    "\n",
    "    # Calculate the entropy\n",
    "    entropy_words = -sum(prob * math.log2(prob) for prob in prob_words.values())\n",
    "    entropy_chars = -sum(prob * math.log2(prob) for prob in prob_chars.values())\n",
    "\n",
    "    print(f'{file}, Entropy of words: {entropy_words}')\n",
    "    print(f'{file}, Entropy of characters: {entropy_chars}')\n",
    "\n",
    "    #save the results to a file\n",
    "    with open('sample_results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(f'{file}, Entropy of words: {entropy_words}\\n')\n",
    "        f.write(f'{file}, Entropy of characters: {entropy_chars}\\n')\n",
    "\n",
    "    #add values to a list for later use\n",
    "    entropy_words_list.append(entropy_words)\n",
    "    entropy_chars_list.append(entropy_chars)\n",
    "\n",
    "#calculate the average,min,max entropy for words and characters across files\n",
    "average_entropy_words = sum(entropy_words_list) / len(entropy_words_list)\n",
    "average_entropy_chars = sum(entropy_chars_list) / len(entropy_chars_list)\n",
    "min_entropy_words = min(entropy_words_list)\n",
    "min_entropy_chars = min(entropy_chars_list)\n",
    "max_entropy_words = max(entropy_words_list)\n",
    "max_entropy_chars = max(entropy_chars_list)\n",
    "\n",
    "#add values to a file\n",
    "with open('entropy_results.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'\\nAverage entropy of words: {average_entropy_words}\\n')\n",
    "    f.write(f'Average entropy of characters: {average_entropy_chars}\\n')\n",
    "    f.write(f'Min entropy of words: {min_entropy_words}\\n')\n",
    "    f.write(f'Min entropy of characters: {min_entropy_chars}\\n')\n",
    "    f.write(f'Max entropy of words: {max_entropy_words}\\n')\n",
    "    f.write(f'Max entropy of characters: {max_entropy_chars}\\n\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m prob_trigrams \u001b[38;5;241m=\u001b[39m {trigram: freq \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(trigrams) \u001b[38;5;28;01mfor\u001b[39;00m trigram, freq \u001b[38;5;129;01min\u001b[39;00m fdist_trigrams\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate the conditional entropy\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m entropy_bigrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(prob \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog2(prob \u001b[38;5;241m/\u001b[39m prob_chars[bigram[\u001b[38;5;241m0\u001b[39m]]) \u001b[38;5;28;01mfor\u001b[39;00m bigram, prob \u001b[38;5;129;01min\u001b[39;00m prob_bigrams\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m     29\u001b[0m entropy_trigrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28msum\u001b[39m(prob \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog2(prob \u001b[38;5;241m/\u001b[39m prob_bigrams[trigram[:\u001b[38;5;241m2\u001b[39m]]) \u001b[38;5;28;01mfor\u001b[39;00m trigram, prob \u001b[38;5;129;01min\u001b[39;00m prob_trigrams\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConditional entropy of bigrams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentropy_bigrams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialize lists for bigrams and trigrams\n",
    "entropy_bigrams_list = []\n",
    "entropy_trigrams_list = []\n",
    "\n",
    "#repeat operation for all files in the list\n",
    "for file in norm_files_list:\n",
    "     # Open and read the file\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "           \n",
    "    # Function to generate n-grams\n",
    "    def generate_ngrams(text, n):\n",
    "        return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "    # Generate bigrams and trigrams\n",
    "    bigrams = generate_ngrams(text, 2)\n",
    "    trigrams = generate_ngrams(text, 3)\n",
    "\n",
    "    # Calculate the frequency distribution\n",
    "    fdist_bigrams = FreqDist(bigrams)\n",
    "    fdist_trigrams = FreqDist(trigrams)\n",
    "\n",
    "    # Calculate the conditional probabilities\n",
    "    prob_bigrams = {bigram: freq / len(bigrams) for bigram, freq in fdist_bigrams.items()}\n",
    "    prob_trigrams = {trigram: freq / len(trigrams) for trigram, freq in fdist_trigrams.items()}\n",
    "\n",
    "    # Calculate the conditional entropy\n",
    "    entropy_bigrams = -sum(prob * math.log2(prob / prob_chars[bigram[0]]) for bigram, prob in prob_bigrams.items())\n",
    "    entropy_trigrams = -sum(prob * math.log2(prob / prob_bigrams[trigram[:2]]) for trigram, prob in prob_trigrams.items())\n",
    "\n",
    "    print(f'Conditional entropy of bigrams: {entropy_bigrams}')\n",
    "    print(f'Conditional entropy of trigrams: {entropy_trigrams}')\n",
    "\n",
    "    #save the results to a file\n",
    "    with open('entroopy_results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(f'{file}, Conditional entropy of bigrams: {entropy_bigrams}\\n')\n",
    "        f.write(f'{file}, Conditional entropy of trigrams: {entropy_trigrams}\\n')\n",
    "\n",
    "    #add values to a list for later use\n",
    "    entropy_bigrams_list.append(entropy_bigrams)\n",
    "    entropy_trigrams_list.append(entropy_trigrams)\n",
    "\n",
    "#calculate the average,min,max entropy for bigrams and trigrams across files\n",
    "average_entropy_bigrams = sum(entropy_bigrams_list) / len(entropy_bigrams_list)\n",
    "average_entropy_trigrams = sum(entropy_trigrams_list) / len(entropy_trigrams_list)\n",
    "min_entropy_bigrams = min(entropy_bigrams_list)\n",
    "min_entropy_trigrams = min(entropy_trigrams_list)\n",
    "max_entropy_bigrams = max(entropy_bigrams_list)\n",
    "max_entropy_trigrams = max(entropy_trigrams_list)\n",
    "\n",
    "#add values to a file\n",
    "with open('entropy_results.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'\\nAverage conditional entropy of bigrams: {average_entropy_bigrams}\\n')\n",
    "    f.write(f'Average conditional entropy of trigrams: {average_entropy_trigrams}\\n')\n",
    "    f.write(f'Min conditional entropy of bigrams: {min_entropy_bigrams}\\n')\n",
    "    f.write(f'Min conditional entropy of trigrams: {min_entropy_trigrams}\\n')\n",
    "    f.write(f'Max conditional entropy of bigrams: {max_entropy_bigrams}\\n')\n",
    "    f.write(f'Max conditional entropy of trigrams: {max_entropy_trigrams}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
