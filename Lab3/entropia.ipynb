{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rtoit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m fdist_chars \u001b[38;5;241m=\u001b[39m FreqDist(chars)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate the probabilities\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m prob_words \u001b[38;5;241m=\u001b[39m {word: freq \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(words) \u001b[38;5;28;01mfor\u001b[39;00m word, freq \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfdist_words\u001b[49m\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     34\u001b[0m prob_chars \u001b[38;5;241m=\u001b[39m {char: freq \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(chars) \u001b[38;5;28;01mfor\u001b[39;00m char, freq \u001b[38;5;129;01min\u001b[39;00m fdist_chars\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate the entropy\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[1;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#anwsers for task 3 saved in file sample_results.txt\n",
    "#entropy of words and characters for each file and average,min,max values for words and characters\n",
    "#same as result of anylysing the norm files saved in norm_results.txt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.probability import FreqDist\n",
    "import math\n",
    "\n",
    "norm_files_list = ['norm_wiki_en.txt', 'norm_wiki_eo.txt', 'norm_wiki_et.txt', 'norm_wiki_ht.txt', 'norm_wiki_la.txt', 'norm_wiki_nv.txt', 'norm_wiki_so.txt']\n",
    "sample_files_list = ['sample0.txt', 'sample1.txt', 'sample2.txt', 'sample3.txt', 'sample4.txt', 'sample5.txt']\n",
    "work_file = 'sample_results.txt'\n",
    "\n",
    "#initialize lists to store entropy values\n",
    "entropy_words_list = []\n",
    "entropy_chars_list = []\n",
    "\n",
    "#clear the result file\n",
    "with open(work_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('')\n",
    "\n",
    "#repeat operation for all files in the list\n",
    "for file in sample_files_list:\n",
    "    # Open and read the file\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Tokenize the text into words and characters\n",
    "    words = nltk.word_tokenize(text)\n",
    "    chars = list(text)\n",
    "\n",
    "    # Calculate the frequency distribution\n",
    "    fdist_words = FreqDist(words)\n",
    "    fdist_chars = FreqDist(chars)\n",
    "\n",
    "    # Calculate the probabilities\n",
    "    prob_words = {word: freq / len(words) for word, freq in fdist_words.items()}\n",
    "    prob_chars = {char: freq / len(chars) for char, freq in fdist_chars.items()}\n",
    "\n",
    "    # Calculate the entropy\n",
    "    entropy_words = -sum(prob * math.log2(prob) for prob in prob_words.values())\n",
    "    entropy_chars = -sum(prob * math.log2(prob) for prob in prob_chars.values())\n",
    "\n",
    "    print(f'{file}, Entropy of words: {entropy_words}')\n",
    "    print(f'{file}, Entropy of characters: {entropy_chars}')\n",
    "\n",
    "    #save the results to a file\n",
    "    with open(work_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f'{file}, Entropy of words: {entropy_words}\\n')\n",
    "        f.write(f'{file}, Entropy of characters: {entropy_chars}\\n')\n",
    "\n",
    "    #add values to a list for later use\n",
    "    entropy_words_list.append(entropy_words)\n",
    "    entropy_chars_list.append(entropy_chars)\n",
    "\n",
    "#calculate the average,min,max entropy for words and characters across files\n",
    "average_entropy_words = sum(entropy_words_list) / len(entropy_words_list)\n",
    "average_entropy_chars = sum(entropy_chars_list) / len(entropy_chars_list)\n",
    "min_entropy_words = min(entropy_words_list)\n",
    "min_entropy_chars = min(entropy_chars_list)\n",
    "max_entropy_words = max(entropy_words_list)\n",
    "max_entropy_chars = max(entropy_chars_list)\n",
    "\n",
    "#add values to a file\n",
    "with open(work_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f'\\nAverage entropy of words: {average_entropy_words}\\n')\n",
    "    f.write(f'Average entropy of characters: {average_entropy_chars}\\n')\n",
    "    f.write(f'Min entropy of words: {min_entropy_words}\\n')\n",
    "    f.write(f'Min entropy of characters: {min_entropy_chars}\\n')\n",
    "    f.write(f'Max entropy of words: {max_entropy_words}\\n')\n",
    "    f.write(f'Max entropy of characters: {max_entropy_chars}\\n\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample0.txt, Conditional entropy of bigrams: 2.6030061749069673\n",
      "sample0.txt, Conditional entropy of trigrams: 2.0003592449340295\n",
      "sample0.txt, Conditional entropy of quadgrams: 1.5392818308831178\n",
      "sample1.txt, Conditional entropy of bigrams: 3.0712406173916493\n",
      "sample1.txt, Conditional entropy of trigrams: 2.861279684784113\n",
      "sample1.txt, Conditional entropy of quadgrams: 2.326684740548095\n",
      "sample2.txt, Conditional entropy of bigrams: 2.6433573831407045\n",
      "sample2.txt, Conditional entropy of trigrams: 2.467660235739306\n",
      "sample2.txt, Conditional entropy of quadgrams: 1.9397723261083073\n",
      "sample3.txt, Conditional entropy of bigrams: 2.9506574660684595\n",
      "sample3.txt, Conditional entropy of trigrams: 2.627895709506982\n",
      "sample3.txt, Conditional entropy of quadgrams: 2.023991488550604\n",
      "sample4.txt, Conditional entropy of bigrams: 3.9144321758459166\n",
      "sample4.txt, Conditional entropy of trigrams: 4.226828937890713\n",
      "sample4.txt, Conditional entropy of quadgrams: 4.178535148281953\n",
      "sample5.txt, Conditional entropy of bigrams: 3.5230981260850065\n",
      "sample5.txt, Conditional entropy of trigrams: 3.250620854647967\n",
      "sample5.txt, Conditional entropy of quadgrams: 2.834271485616726\n"
     ]
    }
   ],
   "source": [
    "#initialize lists for bigrams and trigrams and quadgrams\n",
    "entropy_bigrams_list = []\n",
    "entropy_trigrams_list = []\n",
    "entropy_quadgrams_list = []\n",
    "\n",
    "#repeat operation for all files in the list\n",
    "for file in sample_files_list:\n",
    "     # Open and read the file\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "           \n",
    "    # Function to generate n-grams\n",
    "    def generate_ngrams(text, n):\n",
    "        return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "    # Generate bigrams and trigrams and quadgrams\n",
    "    bigrams = generate_ngrams(text, 2)\n",
    "    trigrams = generate_ngrams(text, 3)\n",
    "    quadgrams = generate_ngrams(text, 4)\n",
    "\n",
    "    # Calculate the frequency distribution\n",
    "    fdist_bigrams = FreqDist(bigrams)\n",
    "    fdist_trigrams = FreqDist(trigrams)\n",
    "    fdist_quadgrams = FreqDist(quadgrams)\n",
    "\n",
    "    # Calculate the conditional probabilities\n",
    "    prob_bigrams = {bigram: freq / len(bigrams) for bigram, freq in fdist_bigrams.items()}\n",
    "    prob_trigrams = {trigram: freq / len(trigrams) for trigram, freq in fdist_trigrams.items()}\n",
    "    prob_quadgrams = {quadgram: freq / len(quadgrams) for quadgram, freq in fdist_quadgrams.items()}\n",
    "\n",
    "    # Calculate the conditional entropy\n",
    "    entropy_bigrams = -sum(prob * math.log2(prob / prob_chars[bigram[0]]) for bigram, prob in prob_bigrams.items())\n",
    "    entropy_trigrams = -sum(prob * math.log2(prob / prob_bigrams[trigram[:2]]) for trigram, prob in prob_trigrams.items())\n",
    "    entropy_quadgrams = -sum(prob * math.log2(prob / prob_trigrams[quadgram[:3]]) for quadgram, prob in prob_quadgrams.items())\n",
    "\n",
    "    print(f'{file}, Conditional entropy of bigrams: {entropy_bigrams}')\n",
    "    print(f'{file}, Conditional entropy of trigrams: {entropy_trigrams}')\n",
    "    print(f'{file}, Conditional entropy of quadgrams: {entropy_quadgrams}')\n",
    "\n",
    "    #save the results to a file\n",
    "    with open(work_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f'{file}, Conditional entropy of bigrams: {entropy_bigrams}\\n')\n",
    "        f.write(f'{file}, Conditional entropy of trigrams: {entropy_trigrams}\\n')\n",
    "        f.write(f'{file}, Conditional entropy of quadgrams: {entropy_quadgrams}\\n')\n",
    "\n",
    "    #add values to a list for later use\n",
    "    entropy_bigrams_list.append(entropy_bigrams)\n",
    "    entropy_trigrams_list.append(entropy_trigrams)\n",
    "    entropy_quadgrams_list.append(entropy_quadgrams)\n",
    "\n",
    "#calculate the average,min,max entropy for bigrams and trigrams across files\n",
    "average_entropy_bigrams = sum(entropy_bigrams_list) / len(entropy_bigrams_list)\n",
    "average_entropy_trigrams = sum(entropy_trigrams_list) / len(entropy_trigrams_list)\n",
    "average_entropy_quadgrams = sum(entropy_quadgrams_list) / len(entropy_quadgrams_list)\n",
    "min_entropy_bigrams = min(entropy_bigrams_list)\n",
    "min_entropy_trigrams = min(entropy_trigrams_list)\n",
    "min_entropy_quadgrams = min(entropy_quadgrams_list)\n",
    "max_entropy_bigrams = max(entropy_bigrams_list)\n",
    "max_entropy_trigrams = max(entropy_trigrams_list)\n",
    "max_entropy_quadgrams = max(entropy_quadgrams_list)\n",
    "\n",
    "#add values to a file\n",
    "with open(work_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f'\\nAverage conditional entropy of bigrams: {average_entropy_bigrams}\\n')\n",
    "    f.write(f'Average conditional entropy of trigrams: {average_entropy_trigrams}\\n')\n",
    "    f.write(f'Average conditional entropy of quadgrams: {average_entropy_quadgrams}\\n')\n",
    "    f.write(f'Min conditional entropy of bigrams: {min_entropy_bigrams}\\n')\n",
    "    f.write(f'Min conditional entropy of trigrams: {min_entropy_trigrams}\\n')\n",
    "    f.write(f'Min conditional entropy of quadgrams: {min_entropy_quadgrams}\\n')\n",
    "    f.write(f'Max conditional entropy of bigrams: {max_entropy_bigrams}\\n')\n",
    "    f.write(f'Max conditional entropy of trigrams: {max_entropy_trigrams}\\n')\n",
    "    f.write(f'Max conditional entropy of quadgrams: {max_entropy_quadgrams}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
